{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import the necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"train.sentiment.value_counts()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting out the X variable from the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\n# init stemmer\nporter_stemmer=PorterStemmer()\n\ndef my_cool_preprocessor(text):\n    \n    text=text.lower() \n    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n    \n    # stem words\n    words=re.split(\"\\\\s+\",text)\n    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n    return ' '.join(stemmed_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_tokenizer(text):\n    # create a space between special characters \n    text=re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n\n    # split based on whitespace\n    return re.split(\"\\\\s+\",text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning text into something your model can read"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2),tokenizer=my_tokenizer, min_df=2,max_df=0.80,analyzer='word',smooth_idf=False, preprocessor=my_cool_preprocessor,stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)\n, \n#stop_words=\"english\",max_df=0.85, preprocessor=my_cool_preprocessor,\"all\",\"in\",\"the\",\"is\",\"and\"preprocessor=my_cool_preprocessor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizer.vocabulary_\n#vectorizer.stop_words_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the training data into a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=0.30,shuffle=True, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model and evaluating using the validation set "},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc = LinearSVC()\nlsvc.fit(X_train, y_train)\nlsvc_pred = lsvc.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the performance of our model on the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val, lsvc_pred, average=\"macro\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(y_val, lsvc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Getting our test set ready "},{"metadata":{"trusted":true},"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lsvc.predict(test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating an output csv for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('testsubmission_8.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}